{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw buoy data cleaning\n",
    "This cell will clean the buoy data to remove rows with NAs in the Lat/Lon columns, ensure that the format of lat/lon pairs is standardized, remove buoy locations on land, and remove buoy tracks with less than 50 rows (these are assumed to have been destroyed or instruments failed)\n",
    "\n",
    "The resulting cleaned data will be stored in the data/cleaned/buoydata/past folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300025010024370.csv has been deleted for having less than 50 rows\n",
      "All files have been cleaned and saved to the cleaned directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# 1. Initialize directories and paths\n",
    "input_directory = '../data/raw/buoydata/past'\n",
    "output_directory = '../data/cleaned/buoydata/past'\n",
    "removed_rows_output_path = '../data/cleaned/buoydata/removed_rows_past.csv'\n",
    "raster_path = '../data/raw/geospatial/arctic_land.tif'\n",
    "\n",
    "# 2. Clear the output directory if it exists, otherwise create it\n",
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# 3. Create a DataFrame to store removed rows\n",
    "removed_rows_df = pd.DataFrame()\n",
    "\n",
    "# Define the transformer to use EPSG:4326 to EPSG:3413\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3413\", always_xy=True)\n",
    "\n",
    "# Function to project coordinates from WGS 1984 to EPSG 3413\n",
    "def project_to_epsg3413(lat, lon):\n",
    "    try:\n",
    "        # Ensure lat and lon are within valid ranges\n",
    "        if not (-90 <= lat <= 90 and -180 <= lon <= 180):\n",
    "            raise ValueError(\"Invalid latitude or longitude values\")\n",
    "        \n",
    "        # Perform the projection\n",
    "        x, y = transformer.transform(lon, lat)\n",
    "        \n",
    "        # Check for invalid projection results\n",
    "        if np.isinf(x) or np.isinf(y):\n",
    "            raise ValueError(\"Projection resulted in inf values\")\n",
    "        \n",
    "        return x, y\n",
    "    except Exception as e:\n",
    "        print(f\"Projection error for lat={lat}, lon={lon}: {e}\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# Function to normalize latitude values\n",
    "def normalize_lat(lat):\n",
    "    while lat < -90 or lat > 90:\n",
    "        if lat < -90:\n",
    "            lat = -180 - lat\n",
    "        elif lat > 90:\n",
    "            lat = 180 - lat\n",
    "    return lat\n",
    "\n",
    "# Function to normalize longitude values\n",
    "def normalize_lon(lon):\n",
    "    while lon < -180 or lon > 180:\n",
    "        if lon < -180:\n",
    "            lon += 360\n",
    "        elif lon > 180:\n",
    "            lon -= 360\n",
    "    return lon\n",
    "\n",
    "# Open the raster file\n",
    "with rasterio.open(raster_path) as src:\n",
    "    # Read the raster data\n",
    "    raster_data = src.read(1)\n",
    "    affine_transform = src.transform\n",
    "\n",
    "    # Function to check if a point overlaps with raster cells with value=1\n",
    "    def overlaps_raster_value_one(lat, lon):\n",
    "        if pd.isna(lat) or pd.isna(lon):\n",
    "            return False\n",
    "        x, y = project_to_epsg3413(lat, lon)\n",
    "        try:\n",
    "            row, col = src.index(x, y)\n",
    "            if 0 <= row < raster_data.shape[0] and 0 <= col < raster_data.shape[1]:\n",
    "                return raster_data[row, col] == 1\n",
    "        except ValueError:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "    # 4. Iterate through each file in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            input_file_path = os.path.join(input_directory, filename)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(input_file_path)\n",
    "            \n",
    "            # a. Remove rows with NAs in Lat or Lon columns\n",
    "            df_cleaned = df.dropna(subset=['Lat', 'Lon'])\n",
    "\n",
    "            # b. Delete duplicate rows\n",
    "            df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "            # c. Normalize lat/lon values\n",
    "            df_cleaned['Lat'] = df_cleaned['Lat'].apply(normalize_lat)\n",
    "            df_cleaned['Lon'] = df_cleaned['Lon'].apply(normalize_lon)\n",
    "\n",
    "            # d. Add columns with projected coordinates\n",
    "            df_cleaned['x'], df_cleaned['y'] = zip(*df_cleaned.apply(lambda row: project_to_epsg3413(row['Lat'], row['Lon']), axis=1))\n",
    "\n",
    "            # e. Determine which rows overlap with raster cells with value=1\n",
    "            df_cleaned['overlaps'] = df_cleaned.apply(lambda row: overlaps_raster_value_one(row['Lat'], row['Lon']), axis=1)\n",
    "            removed_rows = df_cleaned[df_cleaned['overlaps']]\n",
    "            df_cleaned = df_cleaned[~df_cleaned['overlaps']]\n",
    "\n",
    "            # f. Append removed rows to the DataFrame for validation\n",
    "            removed_rows_df = pd.concat([removed_rows_df, removed_rows])\n",
    "\n",
    "            # g. Drop the 'overlaps' and projected coordinate columns\n",
    "            df_cleaned = df_cleaned.drop(columns=['overlaps', 'x', 'y'])\n",
    "\n",
    "            # h. Save the cleaned data to the output directory unless the file has less than 50 rows\n",
    "            if len(df_cleaned) > 50:\n",
    "                output_file_path = os.path.join(output_directory, filename)\n",
    "                df_cleaned.to_csv(output_file_path, index=False)\n",
    "            else:\n",
    "                print(f'{filename} has been deleted for having less than 50 rows')\n",
    "\n",
    "# 5. Save the removed rows to a CSV for validation\n",
    "removed_rows_df.to_csv(removed_rows_output_path, index=False)\n",
    "\n",
    "# 6. Print a message to indicate that the script has finished\n",
    "print('All files have been cleaned and saved to the cleaned directory')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlggeo2024_aobuoypredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
