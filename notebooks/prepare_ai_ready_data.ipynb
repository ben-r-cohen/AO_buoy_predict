{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing past buoy data and reanalyses for use in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all past buoy data into a single dataframe\n",
    "\n",
    "This section will collect all of the cleaned buoy data and combine them into a single dataframe. A column to represent the day of year (DOY) as an integer is also added. These data will be used (along with weather reanalyses) as training data for the machine learning model. Also removes buoys deployed outside of the arctic (<64 degrees N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all raw buoy CSV files into a single DataFrame and add a new column with the Day of Year (DOY) as an integer\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = '../data/cleaned/buoydata/past'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename the lat and lon columns to Latitude and Longitude\n",
    "combined_df.rename(columns={'Lat': 'Latitude', 'Lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# Pad Month, Day, Hour, Min, and Sec columns with leading zeros\n",
    "combined_df['Month'] = combined_df['Month'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Day'] = combined_df['Day'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Hour'] = combined_df['Hour'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Min'] = combined_df['Min'].apply(lambda x: f'{x:02}')\n",
    "combined_df['Sec'] = combined_df['Sec'].apply(lambda x: f'{x:02}')\n",
    "\n",
    "# Create a new column called datetime by combining Year, Month, Day, Hour, Min, and Sec columns\n",
    "combined_df['datetime'] = pd.to_datetime(combined_df['Year'].astype(str) + '-' +\n",
    "                                         combined_df['Month'].astype(str) + '-' +\n",
    "                                         combined_df['Day'].astype(str) + ' ' +\n",
    "                                         combined_df['Hour'].astype(str) + ':' +\n",
    "                                         combined_df['Min'].astype(str) + ':' +\n",
    "                                         combined_df['Sec'].astype(str))\n",
    "\n",
    "# Add a new column with the Day of Year (DOY) as an integer\n",
    "combined_df['DOY'] = combined_df['datetime'].dt.dayofyear\n",
    "\n",
    "# Iterate through the combined_df by BuoyID\n",
    "for buoy_id, group in combined_df.groupby('BuoyID'):\n",
    "    # Sort the records for each BuoyID by datetime from oldest to newest\n",
    "    group = group.sort_values(by='datetime')\n",
    "    \n",
    "    # Check if the first row of the sorted data has a latitude value less than 64\n",
    "    if group.iloc[0]['Latitude'] < 64:\n",
    "        # Remove the entire BuoyID from the dataset\n",
    "        combined_df = combined_df[combined_df['BuoyID'] != buoy_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate ERA5 to buoy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable: ERA5_10m_u_component_of_wind\n",
      "Finished processing ERA5_10m_u_component_of_wind\n",
      "Processing variable: ERA5_10m_v_component_of_wind\n",
      "Finished processing ERA5_10m_v_component_of_wind\n",
      "Processing variable: ERA5_100m_u_component_of_wind\n",
      "Finished processing ERA5_100m_u_component_of_wind\n",
      "Processing variable: ERA5_100m_v_component_of_wind\n",
      "Finished processing ERA5_100m_v_component_of_wind\n",
      "Processing variable: ERA5_sea_ice_cover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benem\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:363: UserWarning: Warning: converting a masked element to nan.\n",
      "  arr[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing ERA5_sea_ice_cover\n",
      "All variables have been processed and interpolated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from scipy.spatial import cKDTree\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Define paths to the NetCDF files and their corresponding variables\n",
    "netcdf_files = {\n",
    "    'ERA5_10m_u_component_of_wind': '../data/raw/reanalyses/ERA5/era5_10m_u_component_of_wind_2023.nc',\n",
    "    'ERA5_10m_v_component_of_wind': '../data/raw/reanalyses/ERA5/era5_10m_v_component_of_wind_2023.nc',\n",
    "    'ERA5_100m_u_component_of_wind': '../data/raw/reanalyses/ERA5/era5_100m_u_component_of_wind_2023.nc',\n",
    "    'ERA5_100m_v_component_of_wind': '../data/raw/reanalyses/ERA5/era5_100m_v_component_of_wind_2023.nc',\n",
    "    'ERA5_sea_ice_cover': '../data/raw/reanalyses/ERA5/era5_sea_ice_cover_2023.nc',\n",
    "}\n",
    "\n",
    "# Load the combined DataFrame\n",
    "# combined_df should already exist with 'datetime', 'Latitude', and 'Longitude' columns\n",
    "# Example:\n",
    "# combined_df = pd.read_csv('path_to_combined_df.csv')\n",
    "\n",
    "# Add a timestamp column to combined_df\n",
    "combined_df['timestamp'] = combined_df['datetime'].apply(lambda x: int(x.replace(tzinfo=timezone.utc).timestamp()))\n",
    "\n",
    "# Iterate over each variable and interpolate values\n",
    "for variable, file_path in netcdf_files.items():\n",
    "    print(f\"Processing variable: {variable}\")\n",
    "    \n",
    "    # Open the NetCDF file\n",
    "    ds = nc.Dataset(file_path)\n",
    "    \n",
    "    # Extract the necessary variables\n",
    "    valid_time = ds.variables['valid_time'][:]\n",
    "    latitudes = ds.variables['latitude'][:]\n",
    "    longitudes = ds.variables['longitude'][:]\n",
    "    data_array = ds.variables[list(ds.variables.keys())[-1]][:]  # Assuming last variable is the data\n",
    "\n",
    "    # Check dimensions and adjust for 3D arrays\n",
    "    if len(data_array.shape) == 4:  # Time, Level, Lat, Lon\n",
    "        data_array = data_array[:, 0, :, :]  # Take the first level\n",
    "\n",
    "    # Create a KDTree for spatial lookup\n",
    "    lat_lon_pairs = np.array([(lat, lon) for lat in latitudes for lon in longitudes])\n",
    "    tree = cKDTree(lat_lon_pairs)\n",
    "\n",
    "    # Add a new column for the variable in combined_df\n",
    "    combined_df[variable] = np.nan\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in combined_df.iterrows():\n",
    "        # Find the closest time index\n",
    "        timestamp = row['timestamp']\n",
    "        time_diffs = np.abs(valid_time - timestamp)\n",
    "        closest_time_index = np.argmin(time_diffs)\n",
    "\n",
    "        # Skip if out of bounds\n",
    "        if closest_time_index < 0 or closest_time_index >= data_array.shape[0]:\n",
    "            print(f\"Skipping row {index} due to time out of bounds\")\n",
    "            continue\n",
    "\n",
    "        # Extract the corresponding slice\n",
    "        data_slice = data_array[closest_time_index, :, :]\n",
    "\n",
    "        # Find the closest grid point\n",
    "        lat_lon = (row['Latitude'], row['Longitude'])\n",
    "        _, closest_point_index = tree.query(lat_lon)\n",
    "        closest_lat, closest_lon = lat_lon_pairs[closest_point_index]\n",
    "\n",
    "        # Find indices of the closest latitude and longitude\n",
    "        lat_index = np.where(latitudes == closest_lat)[0][0]\n",
    "        lon_index = np.where(longitudes == closest_lon)[0][0]\n",
    "\n",
    "        # Assign the interpolated value to the DataFrame\n",
    "        combined_df.at[index, variable] = data_slice[lat_index, lon_index]\n",
    "\n",
    "    print(f\"Finished processing {variable}\")\n",
    "\n",
    "# Save the updated DataFrame\n",
    "# combined_df.to_csv('path_to_updated_combined_df.csv', index=False)\n",
    "\n",
    "# Print completion message\n",
    "print(\"All variables have been processed and interpolated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate IBCAO v5 bathymetry to buoy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Load the georeferenced raster file\n",
    "raster_path = '../data/raw/geospatial/ibcao_v5_2024_100m_depth.tiff'\n",
    "\n",
    "with rasterio.open(raster_path) as raster:\n",
    "    # Get raster metadata\n",
    "    raster_data = raster.read(1)  # Load raster band data\n",
    "    transform = raster.transform  # Affine transformation matrix\n",
    "    nodata = raster.nodata  # NoData value for the raster\n",
    "\n",
    "    # Create a transformer to convert coordinates from WGS 1984 (EPSG:4326) to the raster's CRS (EPSG:3996)\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", raster.crs, always_xy=True)\n",
    "\n",
    "    # Function to get row and column indices for latitude and longitude\n",
    "    def get_row_col(x, y, transform):\n",
    "        col, row = ~transform * (x, y)\n",
    "        return int(row), int(col)\n",
    "\n",
    "    # Create a function to get raster values using numpy indexing\n",
    "    def get_raster_values(latitudes, longitudes):\n",
    "        # Transform WGS 1984 coordinates to the raster CRS\n",
    "        transformed_coords = transformer.transform(longitudes, latitudes)\n",
    "        x_coords, y_coords = transformed_coords\n",
    "\n",
    "        # Get row and column indices\n",
    "        rows, cols = zip(*[get_row_col(x, y, transform) for x, y in zip(x_coords, y_coords)])\n",
    "        rows = np.array(rows)\n",
    "        cols = np.array(cols)\n",
    "\n",
    "        # Ensure indices are within bounds\n",
    "        valid_mask = (\n",
    "            (rows >= 0) & (rows < raster_data.shape[0]) &\n",
    "            (cols >= 0) & (cols < raster_data.shape[1])\n",
    "        )\n",
    "        values = np.full(latitudes.shape, np.nan)  # Initialize output array with NaN\n",
    "        values[valid_mask] = raster_data[rows[valid_mask], cols[valid_mask]]\n",
    "\n",
    "        # Replace nodata values with NaN\n",
    "        if nodata is not None:\n",
    "            values[values == nodata] = np.nan\n",
    "        return values\n",
    "\n",
    "# Assuming combined_df is already defined and contains 'Latitude' and 'Longitude' columns\n",
    "# Example: combined_df = pd.read_csv('path_to_your_combined_df.csv')\n",
    "\n",
    "    # Extract raster values for all lat/lon pairs\n",
    "    combined_df['IBCAOv5_bathymetry'] = get_raster_values(\n",
    "        combined_df['Latitude'].values,\n",
    "        combined_df['Longitude'].values\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuoyID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>Sec</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>GPSdelay</th>\n",
       "      <th>...</th>\n",
       "      <th>Batt</th>\n",
       "      <th>datetime</th>\n",
       "      <th>DOY</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ERA5_10m_u_component_of_wind</th>\n",
       "      <th>ERA5_10m_v_component_of_wind</th>\n",
       "      <th>ERA5_100m_u_component_of_wind</th>\n",
       "      <th>ERA5_100m_v_component_of_wind</th>\n",
       "      <th>ERA5_sea_ice_cover</th>\n",
       "      <th>IBCAOv5_bathymetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>00</td>\n",
       "      <td>07</td>\n",
       "      <td>32</td>\n",
       "      <td>77.33740</td>\n",
       "      <td>-138.15785</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 00:07:32</td>\n",
       "      <td>219</td>\n",
       "      <td>1691366852</td>\n",
       "      <td>2.133270</td>\n",
       "      <td>-1.722595</td>\n",
       "      <td>2.605240</td>\n",
       "      <td>-2.824326</td>\n",
       "      <td>0.48999</td>\n",
       "      <td>-3700.891113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>00</td>\n",
       "      <td>51</td>\n",
       "      <td>05</td>\n",
       "      <td>77.33538</td>\n",
       "      <td>-138.13705</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 00:51:05</td>\n",
       "      <td>219</td>\n",
       "      <td>1691369465</td>\n",
       "      <td>1.552002</td>\n",
       "      <td>-2.264008</td>\n",
       "      <td>1.641525</td>\n",
       "      <td>-3.230820</td>\n",
       "      <td>0.48999</td>\n",
       "      <td>-3691.111084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>40</td>\n",
       "      <td>77.33479</td>\n",
       "      <td>-138.13317</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 01:01:40</td>\n",
       "      <td>219</td>\n",
       "      <td>1691370100</td>\n",
       "      <td>1.552002</td>\n",
       "      <td>-2.264008</td>\n",
       "      <td>1.641525</td>\n",
       "      <td>-3.230820</td>\n",
       "      <td>0.48999</td>\n",
       "      <td>-3697.583984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>21</td>\n",
       "      <td>77.33148</td>\n",
       "      <td>-138.11950</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 02:01:21</td>\n",
       "      <td>219</td>\n",
       "      <td>1691373681</td>\n",
       "      <td>1.249054</td>\n",
       "      <td>-2.767960</td>\n",
       "      <td>1.250229</td>\n",
       "      <td>-3.651215</td>\n",
       "      <td>0.47995</td>\n",
       "      <td>-3698.184082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300025010734900</td>\n",
       "      <td>2023</td>\n",
       "      <td>08</td>\n",
       "      <td>07</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>77.32867</td>\n",
       "      <td>-138.12018</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-08-07 03:01:11</td>\n",
       "      <td>219</td>\n",
       "      <td>1691377271</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>-3.224045</td>\n",
       "      <td>0.595322</td>\n",
       "      <td>-4.391693</td>\n",
       "      <td>0.47995</td>\n",
       "      <td>-3699.036377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BuoyID  Year Month Day Hour Min Sec  Latitude  Longitude  \\\n",
       "0  300025010734900  2023    08  07   00  07  32  77.33740 -138.15785   \n",
       "1  300025010734900  2023    08  07   00  51  05  77.33538 -138.13705   \n",
       "2  300025010734900  2023    08  07   01  01  40  77.33479 -138.13317   \n",
       "3  300025010734900  2023    08  07   02  01  21  77.33148 -138.11950   \n",
       "4  300025010734900  2023    08  07   03  01  11  77.32867 -138.12018   \n",
       "\n",
       "   GPSdelay  ...  Batt            datetime  DOY   timestamp  \\\n",
       "0         0  ...    13 2023-08-07 00:07:32  219  1691366852   \n",
       "1         0  ...    13 2023-08-07 00:51:05  219  1691369465   \n",
       "2         0  ...    13 2023-08-07 01:01:40  219  1691370100   \n",
       "3         0  ...    13 2023-08-07 02:01:21  219  1691373681   \n",
       "4         0  ...    13 2023-08-07 03:01:11  219  1691377271   \n",
       "\n",
       "   ERA5_10m_u_component_of_wind  ERA5_10m_v_component_of_wind  \\\n",
       "0                      2.133270                     -1.722595   \n",
       "1                      1.552002                     -2.264008   \n",
       "2                      1.552002                     -2.264008   \n",
       "3                      1.249054                     -2.767960   \n",
       "4                      0.722733                     -3.224045   \n",
       "\n",
       "  ERA5_100m_u_component_of_wind  ERA5_100m_v_component_of_wind  \\\n",
       "0                      2.605240                      -2.824326   \n",
       "1                      1.641525                      -3.230820   \n",
       "2                      1.641525                      -3.230820   \n",
       "3                      1.250229                      -3.651215   \n",
       "4                      0.595322                      -4.391693   \n",
       "\n",
       "   ERA5_sea_ice_cover  IBCAOv5_bathymetry  \n",
       "0             0.48999        -3700.891113  \n",
       "1             0.48999        -3691.111084  \n",
       "2             0.48999        -3697.583984  \n",
       "3             0.47995        -3698.184082  \n",
       "4             0.47995        -3699.036377  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more data to the spreadsheet (wind vector and displacement/heading columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating wind magnitude and wind angle...\n",
      "Wind magnitude and wind angle calculated successfully.\n",
      "            BuoyID  Year Month Day Hour Min Sec  Latitude  Longitude  \\\n",
      "0  300025010734900  2023    08  07   00  07  32  77.33740 -138.15785   \n",
      "1  300025010734900  2023    08  07   00  51  05  77.33538 -138.13705   \n",
      "2  300025010734900  2023    08  07   01  01  40  77.33479 -138.13317   \n",
      "3  300025010734900  2023    08  07   02  01  21  77.33148 -138.11950   \n",
      "4  300025010734900  2023    08  07   03  01  11  77.32867 -138.12018   \n",
      "\n",
      "   GPSdelay  ...  wind_angle_10m  wind_magnitude_100m  wind_angle_100m  \\\n",
      "0         0  ...      -38.920541             3.842407       -47.310660   \n",
      "1         0  ...      -55.568936             3.623921       -63.065641   \n",
      "2         0  ...      -55.568936             3.623921       -63.065641   \n",
      "3         0  ...      -65.712514             3.859332       -71.098052   \n",
      "4         0  ...      -77.364915             4.431859       -82.280252   \n",
      "\n",
      "   displacement  heading  time_to_next_position ERA5_wind_magnitude_10m  \\\n",
      "0           0.0      0.0                    0.0                2.741929   \n",
      "1           0.0      0.0                    0.0                2.744894   \n",
      "2           0.0      0.0                    0.0                2.744894   \n",
      "3           0.0      0.0                    0.0                3.036731   \n",
      "4           0.0      0.0                    0.0                3.304059   \n",
      "\n",
      "   ERA5_wind_angle_10m  ERA5_wind_magnitude_100m  ERA5_wind_angle_100m  \n",
      "0           -38.920541                  3.842407            -47.310660  \n",
      "1           -55.568936                  3.623921            -63.065641  \n",
      "2           -55.568936                  3.623921            -63.065641  \n",
      "3           -65.712514                  3.859332            -71.098052  \n",
      "4           -77.364915                  4.431859            -82.280252  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "Calculating displacement, heading, and time to next position...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benem\\AppData\\Local\\Temp\\ipykernel_12636\\835004161.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combined_df = combined_df.groupby('BuoyID').apply(calculate_displacement_and_heading).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displacement, heading, and time to next position calculated successfully.\n",
      "   BuoyID  Year Month Day Hour Min Sec  Latitude  Longitude  GPSdelay  ...  \\\n",
      "0  900115  2023    01  01   00  00  46  81.53036 -149.67551         0  ...   \n",
      "1  900115  2023    01  01   00  30  47  81.53165 -149.68448         0  ...   \n",
      "2  900115  2023    01  01   01  01  17  81.53296 -149.69345         0  ...   \n",
      "3  900115  2023    01  01   01  31  03  81.53421 -149.70296         0  ...   \n",
      "4  900115  2023    01  01   02  00  47  81.53523 -149.71284         0  ...   \n",
      "\n",
      "   wind_angle_10m  wind_magnitude_100m  wind_angle_100m  displacement  \\\n",
      "0      157.049906            10.385153       151.275310      0.000000   \n",
      "1      158.672519            10.493810       152.740733    205.312977   \n",
      "2      158.672519            10.493810       152.740733    206.856929   \n",
      "3      159.048017            10.716345       153.376829    208.707315   \n",
      "4      159.048017            10.716345       153.376829    197.532749   \n",
      "\n",
      "      heading  time_to_next_position ERA5_wind_magnitude_10m  \\\n",
      "0    0.000000                    0.0                7.176650   \n",
      "1  314.323130                 1801.0                7.251635   \n",
      "2  314.768180                 1830.0                7.251635   \n",
      "3  311.761871                 1786.0                7.390317   \n",
      "4  305.046983                 1784.0                7.390317   \n",
      "\n",
      "   ERA5_wind_angle_10m  ERA5_wind_magnitude_100m  ERA5_wind_angle_100m  \n",
      "0           157.049906                 10.385153            151.275310  \n",
      "1           158.672519                 10.493810            152.740733  \n",
      "2           158.672519                 10.493810            152.740733  \n",
      "3           159.048017                 10.716345            153.376829  \n",
      "4           159.048017                 10.716345            153.376829  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from geopy.distance import great_circle  # For calculating displacement\n",
    "import math  # For trigonometric calculations\n",
    "\n",
    "def add_new_columns(combined_df):\n",
    "    print(\"Calculating wind magnitude and wind angle...\")\n",
    "\n",
    "    # Calculate wind magnitude and wind angle\n",
    "    combined_df.loc[:, 'ERA5_wind_magnitude_10m'] = np.sqrt(combined_df['ERA5_10m_u_component_of_wind']**2 + combined_df['ERA5_10m_v_component_of_wind']**2)\n",
    "    combined_df.loc[:, 'ERA5_wind_angle_10m'] = np.degrees(np.arctan2(combined_df['ERA5_10m_v_component_of_wind'], combined_df['ERA5_10m_u_component_of_wind']))\n",
    "    combined_df.loc[:, 'ERA5_wind_magnitude_100m'] = np.sqrt(combined_df['ERA5_100m_u_component_of_wind']**2 + combined_df['ERA5_100m_v_component_of_wind']**2)\n",
    "    combined_df.loc[:, 'ERA5_wind_angle_100m'] = np.degrees(np.arctan2(combined_df['ERA5_100m_v_component_of_wind'], combined_df['ERA5_100m_u_component_of_wind']))\n",
    "    \n",
    "    print(\"Wind magnitude and wind angle calculated successfully.\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    print(\"Calculating displacement, heading, and time to next position...\")\n",
    "\n",
    "    # Initialize displacement, heading, and time to next position columns\n",
    "    combined_df.loc[:, 'displacement'] = 0.0\n",
    "    combined_df.loc[:, 'heading'] = 0.0\n",
    "    combined_df.loc[:, 'time_to_next_position'] = 0.0\n",
    "\n",
    "    # Function to calculate displacement, heading, and time to next position for each group\n",
    "    def calculate_displacement_and_heading(group):\n",
    "        group = group.sort_values(by='datetime').reset_index(drop=True)\n",
    "        for i in range(1, len(group)):\n",
    "            # Ensure latitude and longitude values are passed as numeric arguments\n",
    "            prev_point = (group.loc[i-1, 'Latitude'], group.loc[i-1, 'Longitude'])\n",
    "            curr_point = (group.loc[i, 'Latitude'], group.loc[i, 'Longitude'])\n",
    "\n",
    "            # Calculate displacement\n",
    "            group.loc[i, 'displacement'] = great_circle(prev_point, curr_point).meters\n",
    "\n",
    "            # Calculate heading\n",
    "            lat1, lon1 = map(math.radians, prev_point)\n",
    "            lat2, lon2 = map(math.radians, curr_point)\n",
    "\n",
    "            dlon = lon2 - lon1\n",
    "            x = math.sin(dlon) * math.cos(lat2)\n",
    "            y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1) * math.cos(lat2) * math.cos(dlon))\n",
    "            initial_heading = math.atan2(x, y)\n",
    "            initial_heading = math.degrees(initial_heading)\n",
    "            compass_heading = (initial_heading + 360) % 360\n",
    "\n",
    "            group.loc[i, 'heading'] = compass_heading\n",
    "\n",
    "            # Calculate time to next position\n",
    "            time_diff = (group.loc[i, 'datetime'] - group.loc[i-1, 'datetime']).total_seconds()\n",
    "            group.loc[i, 'time_to_next_position'] = time_diff\n",
    "        return group\n",
    "\n",
    "    # Apply the function to each group\n",
    "    combined_df = combined_df.groupby('BuoyID').apply(calculate_displacement_and_heading).reset_index(drop=True)\n",
    "\n",
    "    print(\"Displacement, heading, and time to next position calculated successfully.\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Add new columns for wind magnitude, angle, displacement, heading, and time to next position\n",
    "combined_df = add_new_columns(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated buoy data saved to interpolated_buoy_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save the combined_df to a CSV file\n",
    "output_csv_path = 'interpolated_buoy_data.csv'\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Interpolated buoy data saved to {output_csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for BuoyID 300234060330560 saved to random_buoy_300234060330560.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pick a random BuoyID from combined_df\n",
    "random_buoy_id = np.random.choice(combined_df['BuoyID'].unique())\n",
    "\n",
    "# Filter the dataframe for the selected BuoyID\n",
    "random_buoy_df = combined_df[combined_df['BuoyID'] == random_buoy_id]\n",
    "\n",
    "# Save the filtered dataframe to a new CSV file\n",
    "random_buoy_csv_path = f'random_buoy_{random_buoy_id}.csv'\n",
    "random_buoy_df.to_csv(random_buoy_csv_path, index=False)\n",
    "\n",
    "print(f\"Data for BuoyID {random_buoy_id} saved to {random_buoy_csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting slice for variable: ERA5_10m_u_component_of_wind\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# Define the timestamp for which we want to extract the slices\n",
    "target_timestamp = 1693519200\n",
    "\n",
    "# Define a dictionary to store the slices\n",
    "slices = {}\n",
    "\n",
    "# Iterate over each variable and extract the corresponding slice\n",
    "for variable, file_path in netcdf_files.items():\n",
    "    print(f\"Extracting slice for variable: {variable}\")\n",
    "    \n",
    "    # Open the NetCDF file\n",
    "    ds = nc.Dataset(file_path)\n",
    "    \n",
    "    # Extract the necessary variables\n",
    "    valid_time = ds.variables['valid_time'][:]\n",
    "    data_array = ds.variables[list(ds.variables.keys())[-1]][:]  # Assuming last variable is the data\n",
    "\n",
    "    # Check dimensions and adjust for 3D arrays\n",
    "    if len(data_array.shape) == 4:  # Time, Level, Lat, Lon\n",
    "        data_array = data_array[:, 0, :, :]  # Take the first level\n",
    "\n",
    "    # Find the closest time index\n",
    "    time_diffs = np.abs(valid_time - target_timestamp)\n",
    "    closest_time_index = np.argmin(time_diffs)\n",
    "\n",
    "    # Extract the corresponding slice\n",
    "    data_slice = data_array[closest_time_index, :, :]\n",
    "\n",
    "    # Store the slice in the dictionary\n",
    "    slices[variable] = data_slice\n",
    "\n",
    "    # Save the slice to a file for validation\n",
    "    np.save(f'{variable}_slice_{target_timestamp}.npy', data_slice)\n",
    "\n",
    "    print(f\"Slice for {variable} saved successfully.\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"All slices have been extracted and saved for validation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
